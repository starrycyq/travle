"""
æ•°æ®åº“ä¼˜åŒ–å·¥å…·
æä¾›æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–ã€æŸ¥è¯¢åˆ†æå’Œæ€§èƒ½è°ƒä¼˜åŠŸèƒ½
"""

import sqlite3
import logging
from typing import List, Dict, Any
from datetime import datetime

logger = logging.getLogger(__name__)

class DatabaseOptimizer:
    """æ•°æ®åº“ä¼˜åŒ–å™¨"""
    
    def __init__(self, db_path: str = None):
        self.db_path = db_path or './preferences.db'
        self.conn = None
    
    def connect(self):
        """è¿æ¥åˆ°æ•°æ®åº“"""
        self.conn = sqlite3.connect(self.db_path)
        self.conn.row_factory = sqlite3.Row
        return self.conn
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
            self.conn = None
    
    def analyze_tables(self) -> List[Dict[str, Any]]:
        """åˆ†ææ•°æ®åº“è¡¨ç»“æ„"""
        self.connect()
        cursor = self.conn.cursor()
        
        tables = []
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        table_names = [row[0] for row in cursor.fetchall()]
        
        for table_name in table_names:
            # è·å–è¡¨ä¿¡æ¯
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = cursor.fetchall()
            
            # è·å–ç´¢å¼•ä¿¡æ¯
            cursor.execute(f"PRAGMA index_list({table_name})")
            indexes = cursor.fetchall()
            
            # è·å–è¡¨å¤§å°
            cursor.execute(f"SELECT COUNT(*) as row_count FROM {table_name}")
            row_count = cursor.fetchone()[0]
            
            tables.append({
                'name': table_name,
                'columns': [{'cid': col[0], 'name': col[1], 'type': col[2], 
                            'notnull': col[3], 'default': col[4], 'pk': col[5]} 
                           for col in columns],
                'indexes': indexes,
                'row_count': row_count
            })
        
        self.close()
        return tables
    
    def get_recommended_indexes(self) -> List[Dict[str, str]]:
        """è·å–æ¨èçš„ç´¢å¼•"""
        recommendations = []
        
        # åˆ†ææŸ¥è¯¢æ¨¡å¼å¹¶æ¨èç´¢å¼•
        # 1. preferencesè¡¨æŸ¥è¯¢æ¨¡å¼
        recommendations.extend([
            {
                'table': 'preferences',
                'column': 'destination',
                'index_name': 'idx_preferences_destination',
                'reason': 'æŒ‰ç›®çš„åœ°æŸ¥è¯¢ç”¨æˆ·åå¥½',
                'query_example': 'SELECT * FROM preferences WHERE destination = ?'
            },
            {
                'table': 'preferences',
                'column': 'timestamp',
                'index_name': 'idx_preferences_timestamp',
                'reason': 'æŒ‰æ—¶é—´èŒƒå›´æŸ¥è¯¢åå¥½è®°å½•',
                'query_example': 'SELECT * FROM preferences WHERE timestamp BETWEEN ? AND ?'
            }
        ])
        
        # 2. community_postè¡¨æŸ¥è¯¢æ¨¡å¼
        recommendations.extend([
            {
                'table': 'community_post',
                'column': 'create_time',
                'index_name': 'idx_community_post_create_time',
                'reason': 'æŒ‰æ—¶é—´æ’åºç¤¾åŒºåŠ¨æ€',
                'query_example': 'SELECT * FROM community_post ORDER BY create_time DESC'
            },
            {
                'table': 'community_post',
                'column': 'destination',
                'index_name': 'idx_community_post_destination',
                'reason': 'æŒ‰ç›®çš„åœ°ç­›é€‰ç¤¾åŒºåŠ¨æ€',
                'query_example': 'SELECT * FROM community_post WHERE destination = ?'
            },
            {
                'table': 'community_post',
                'column': 'like_count',
                'index_name': 'idx_community_post_like_count',
                'reason': 'æŒ‰ç‚¹èµæ•°æ’åºçƒ­é—¨åŠ¨æ€',
                'query_example': 'SELECT * FROM community_post ORDER BY like_count DESC'
            }
        ])
        
        # 3. community_commentè¡¨æŸ¥è¯¢æ¨¡å¼
        recommendations.extend([
            {
                'table': 'community_comment',
                'column': 'post_id',
                'index_name': 'idx_community_comment_post_id',
                'reason': 'æŒ‰å¸–å­IDæŸ¥è¯¢è¯„è®º',
                'query_example': 'SELECT * FROM community_comment WHERE post_id = ?'
            },
            {
                'table': 'community_comment',
                'column': 'create_time',
                'index_name': 'idx_community_comment_create_time',
                'reason': 'æŒ‰æ—¶é—´æ’åºè¯„è®º',
                'query_example': 'SELECT * FROM community_comment WHERE post_id = ? ORDER BY create_time'
            }
        ])
        
        return recommendations
    
    def create_indexes(self, indexes: List[Dict[str, str]] = None) -> Dict[str, Any]:
        """åˆ›å»ºç´¢å¼•"""
        if indexes is None:
            indexes = self.get_recommended_indexes()
        
        self.connect()
        cursor = self.conn.cursor()
        
        results = {
            'created': [],
            'skipped': [],
            'errors': []
        }
        
        for index_info in indexes:
            table = index_info['table']
            column = index_info['column']
            index_name = index_info['index_name']
            
            try:
                # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å·²å­˜åœ¨
                cursor.execute(f"SELECT name FROM sqlite_master WHERE type='index' AND name='{index_name}'")
                if cursor.fetchone():
                    logger.info(f"ç´¢å¼•å·²å­˜åœ¨: {index_name}")
                    results['skipped'].append(index_name)
                    continue
                
                # åˆ›å»ºç´¢å¼•
                create_sql = f"CREATE INDEX {index_name} ON {table}({column})"
                cursor.execute(create_sql)
                logger.info(f"åˆ›å»ºç´¢å¼•: {index_name} ON {table}({column})")
                results['created'].append(index_name)
                
            except Exception as e:
                error_msg = f"åˆ›å»ºç´¢å¼•å¤±è´¥ {index_name}: {e}"
                logger.error(error_msg)
                results['errors'].append(error_msg)
        
        self.conn.commit()
        self.close()
        
        return results
    
    def analyze_query_performance(self, query: str, params: tuple = None) -> Dict[str, Any]:
        """åˆ†ææŸ¥è¯¢æ€§èƒ½"""
        self.connect()
        cursor = self.conn.cursor()
        
        # å¯ç”¨SQLiteçš„æŸ¥è¯¢è®¡åˆ’
        cursor.execute("EXPLAIN QUERY PLAN " + query, params or ())
        query_plan = cursor.fetchall()
        
        # æ‰§è¡ŒæŸ¥è¯¢è·å–å®é™…æ€§èƒ½
        import time
        start_time = time.perf_counter()
        cursor.execute(query, params or ())
        results = cursor.fetchall()
        execution_time = time.perf_counter() - start_time
        
        # è·å–æŸ¥è¯¢ç»Ÿè®¡ä¿¡æ¯
        row_count = len(results)
        
        analysis = {
            'query': query,
            'params': params,
            'execution_time': execution_time,
            'row_count': row_count,
            'query_plan': query_plan,
            'suggestions': []
        }
        
        # åˆ†ææŸ¥è¯¢è®¡åˆ’å¹¶æä¾›å»ºè®®
        plan_text = ' '.join(str(row) for row in query_plan)
        
        if 'SCAN TABLE' in plan_text and 'USING INDEX' not in plan_text:
            analysis['suggestions'].append(
                "å»ºè®®: æŸ¥è¯¢æ‰§è¡Œå…¨è¡¨æ‰«æï¼Œè€ƒè™‘æ·»åŠ ç´¢å¼•"
            )
        
        if 'TEMPORARY B-TREE' in plan_text:
            analysis['suggestions'].append(
                "å»ºè®®: æŸ¥è¯¢åˆ›å»ºä¸´æ—¶ç´¢å¼•ï¼Œè€ƒè™‘æ·»åŠ åˆé€‚çš„ç´¢å¼•"
            )
        
        if execution_time > 0.1:  # è¶…è¿‡100ms
            analysis['suggestions'].append(
                f"è­¦å‘Š: æŸ¥è¯¢æ‰§è¡Œæ—¶é—´è¾ƒé•¿ ({execution_time:.3f}s)ï¼Œå»ºè®®ä¼˜åŒ–"
            )
        
        self.close()
        return analysis
    
    def optimize_database(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®åº“ä¼˜åŒ–"""
        logger.info("å¼€å§‹æ•°æ®åº“ä¼˜åŒ–")
        
        # 1. åˆ†æå½“å‰è¡¨ç»“æ„
        tables = self.analyze_tables()
        logger.info(f"åˆ†æå®Œæˆï¼Œå…± {len(tables)} ä¸ªè¡¨")
        
        # 2. åˆ›å»ºæ¨èçš„ç´¢å¼•
        recommendations = self.get_recommended_indexes()
        index_results = self.create_indexes(recommendations)
        
        # 3. åˆ†æå…³é”®æŸ¥è¯¢æ€§èƒ½
        key_queries = [
            ("SELECT * FROM preferences WHERE destination = ?", ('åŒ—äº¬',)),
            ("SELECT * FROM community_post ORDER BY create_time DESC LIMIT 20", ()),
            ("SELECT * FROM community_comment WHERE post_id = ? ORDER BY create_time", (1,)),
            ("SELECT * FROM community_post WHERE destination = ? ORDER BY like_count DESC", ('ä¸Šæµ·',))
        ]
        
        query_analyses = []
        for query, params in key_queries:
            analysis = self.analyze_query_performance(query, params)
            query_analyses.append(analysis)
        
        # 4. ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
        report = self.generate_optimization_report(
            tables, index_results, query_analyses
        )
        
        logger.info("æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")
        return report
    
    def generate_optimization_report(self, tables, index_results, query_analyses):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("æ•°æ®åº“ä¼˜åŒ–æŠ¥å‘Š")
        report_lines.append("=" * 80)
        report_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"æ•°æ®åº“: {self.db_path}")
        report_lines.append("")
        
        # è¡¨ç»“æ„åˆ†æ
        report_lines.append("ğŸ“Š è¡¨ç»“æ„åˆ†æ")
        for table in tables:
            report_lines.append(f"  è¡¨: {table['name']}")
            report_lines.append(f"    è¡Œæ•°: {table['row_count']:,}")
            report_lines.append(f"    åˆ—æ•°: {len(table['columns'])}")
            report_lines.append(f"    ç´¢å¼•æ•°: {len(table['indexes'])}")
        report_lines.append("")
        
        # ç´¢å¼•ä¼˜åŒ–ç»“æœ
        report_lines.append("ğŸ”§ ç´¢å¼•ä¼˜åŒ–")
        report_lines.append(f"  åˆ›å»ºç´¢å¼•: {len(index_results['created'])} ä¸ª")
        if index_results['created']:
            report_lines.append("    å·²åˆ›å»º:")
            for idx in index_results['created']:
                report_lines.append(f"    â€¢ {idx}")
        
        report_lines.append(f"  è·³è¿‡ç´¢å¼•: {len(index_results['skipped'])} ä¸ª")
        report_lines.append(f"  é”™è¯¯: {len(index_results['errors'])} ä¸ª")
        if index_results['errors']:
            report_lines.append("    é”™è¯¯è¯¦æƒ…:")
            for error in index_results['errors']:
                report_lines.append(f"    â€¢ {error}")
        report_lines.append("")
        
        # æŸ¥è¯¢æ€§èƒ½åˆ†æ
        report_lines.append("âš¡ æŸ¥è¯¢æ€§èƒ½åˆ†æ")
        for analysis in query_analyses:
            report_lines.append(f"  æŸ¥è¯¢: {analysis['query'][:60]}...")
            report_lines.append(f"    æ‰§è¡Œæ—¶é—´: {analysis['execution_time']:.3f}s")
            report_lines.append(f"    è¿”å›è¡Œæ•°: {analysis['row_count']}")
            
            if analysis['suggestions']:
                report_lines.append("    ä¼˜åŒ–å»ºè®®:")
                for suggestion in analysis['suggestions']:
                    report_lines.append(f"    â€¢ {suggestion}")
            else:
                report_lines.append("    âœ… æŸ¥è¯¢æ€§èƒ½è‰¯å¥½")
            report_lines.append("")
        
        # æ€»ä½“å»ºè®®
        report_lines.append("ğŸ’¡ æ€»ä½“ä¼˜åŒ–å»ºè®®")
        report_lines.append("  1. å®šæœŸè¿è¡Œæ•°æ®åº“ä¼˜åŒ–ï¼ˆå»ºè®®æ¯å‘¨ä¸€æ¬¡ï¼‰")
        report_lines.append("  2. ç›‘æ§æ…¢æŸ¥è¯¢æ—¥å¿—")
        report_lines.append("  3. è€ƒè™‘å¯¹å¤§è¡¨è¿›è¡Œåˆ†åŒº")
        report_lines.append("  4. å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®")
        report_lines.append("  5. å¯ç”¨æ•°æ®åº“è¿æ¥æ± ")
        
        return "\n".join(report_lines)
    
    def vacuum_database(self):
        """æ‰§è¡Œæ•°æ®åº“VACUUMæ“ä½œï¼ˆå‹ç¼©å’Œé‡å»ºæ•°æ®åº“ï¼‰"""
        logger.info("å¼€å§‹æ‰§è¡ŒVACUUMæ“ä½œ")
        self.connect()
        cursor = self.conn.cursor()
        
        try:
            cursor.execute("VACUUM")
            logger.info("VACUUMæ“ä½œå®Œæˆ")
            return True
        except Exception as e:
            logger.error(f"VACUUMæ“ä½œå¤±è´¥: {e}")
            return False
        finally:
            self.close()

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®åº“ä¼˜åŒ–å·¥å…·')
    parser.add_argument('--db-path', default='./preferences.db', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--optimize', action='store_true', help='æ‰§è¡Œå®Œæ•´ä¼˜åŒ–')
    parser.add_argument('--analyze', action='store_true', help='åˆ†ææ•°æ®åº“')
    parser.add_argument('--create-indexes', action='store_true', help='åˆ›å»ºæ¨èç´¢å¼•')
    parser.add_argument('--vacuum', action='store_true', help='æ‰§è¡ŒVACUUMæ“ä½œ')
    parser.add_argument('--output', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    optimizer = DatabaseOptimizer(args.db_path)
    
    if args.analyze:
        tables = optimizer.analyze_tables()
        print(f"åˆ†æå®Œæˆï¼Œå…± {len(tables)} ä¸ªè¡¨")
        for table in tables:
            print(f"\nè¡¨: {table['name']}")
            print(f"  è¡Œæ•°: {table['row_count']:,}")
            print(f"  åˆ—æ•°: {len(table['columns'])}")
            print(f"  ç´¢å¼•æ•°: {len(table['indexes'])}")
    
    if args.create_indexes:
        recommendations = optimizer.get_recommended_indexes()
        print(f"å°†åˆ›å»º {len(recommendations)} ä¸ªç´¢å¼•")
        results = optimizer.create_indexes(recommendations)
        print(f"åˆ›å»ºå®Œæˆ: {len(results['created'])} æˆåŠŸ, {len(results['skipped'])} è·³è¿‡, {len(results['errors'])} é”™è¯¯")
    
    if args.vacuum:
        optimizer.vacuum_database()
    
    if args.optimize:
        report = optimizer.optimize_database()
        print("\n" + report)
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")

if __name__ == '__main__':
    main()